{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential,load_model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D,Dropout,Convolution2D,Activation\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_DIRECTORY = 'image_data'\n",
    "\n",
    "CLASS_MAP = {\n",
    "    \"rock\" : 0,\n",
    "    \"paper\" : 1,\n",
    "    \"scissors\" : 2,\n",
    "    \"none\" : 3\n",
    "}\n",
    "\n",
    "NUM_CLASES = len(CLASS_MAP)\n",
    "\n",
    "def mapper(val):\n",
    "    return CLASS_MAP[val]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.densenet import DenseNet121\n",
    "\n",
    "densent = DenseNet121(include_top=False, weights='imagenet',classes=4,input_shape=(227,227,3))\n",
    "\n",
    "def get_model(base):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(base)\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Convolution2D(NUM_CLASES, (1,1), padding='valid'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[array([[[254, 254, 247],\n        [254, 254, 255],\n        [252, 255, 255],\n        ...,\n        [252, 254, 253],\n        [254, 255, 255],\n        [253, 255, 254]],\n\n       [[255, 254, 255],\n        [ 74,  72,  94],\n        [ 73,  74,  94],\n        ...,\n        [132, 134, 133],\n        [132, 134, 133],\n        [207, 208, 209]],\n\n       [[253, 253, 255],\n        [ 75,  73,  98],\n        [ 75,  75, 102],\n        ...,\n        [133, 136, 137],\n        [134, 137, 138],\n        [207, 209, 210]],\n\n       ...,\n\n       [[255, 255, 255],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        ...,\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [158, 158, 158]],\n\n       [[255, 255, 255],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        ...,\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [158, 158, 158]],\n\n       [[255, 255, 255],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        ...,\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [158, 158, 158]]], dtype=uint8), 'none']\n"
    }
   ],
   "source": [
    "dataset = []\n",
    "\n",
    "for dir in os.listdir(IMG_DIRECTORY):\n",
    "    path = os.path.join(IMG_DIRECTORY, dir)\n",
    "    if not os.path.isdir(path):\n",
    "        continue\n",
    "\n",
    "    for item in os.listdir(path):\n",
    "        if item.startswith(\".\"):\n",
    "            continue\n",
    "        img = cv2.imread(os.path.join(path, item))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (227,227))\n",
    "        \n",
    "        dataset.append([img, dir])\n",
    "\n",
    "print(dataset[5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = zip(*dataset)\n",
    "labels = list(map(mapper, labels))\n",
    "\n",
    "labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "dnet = get_model(densent)\n",
    "\n",
    "dnet.compile(\n",
    "    optimizer = Adam(lr=0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['acc']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "np_train_data = np.array(data)\n",
    "np_train_labels = np.array(labels)\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'model.h5', \n",
    "    monitor='val_acc', \n",
    "    verbose=1, \n",
    "    save_best_only=True, \n",
    "    save_weights_only=True,\n",
    "    mode='auto'\n",
    ")\n",
    "\n",
    "es = EarlyStopping(patience = 3)\n",
    "\n",
    "dnet.fit(\n",
    "    np_train_data,\n",
    "    np_train_labels, \n",
    "    validation_split=0.2,\n",
    "    verbose=2,\n",
    "    epochs=10\n",
    "    )\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitd05e92c4ff814ae7a5a1266bb0863022",
   "display_name": "Python 3.7.7 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}